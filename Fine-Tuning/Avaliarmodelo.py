import torch
import librosa
from transformers import WhisperProcessor, WhisperForConditionalGeneration
import os
import sys

sys.stderr = open(os.devnull, 'w')
logging.set_verbosity_error()
# Configurações
MODEL_PATH = "./whisper-small-finetuned"  
AUDIO_FILE_PATH = "CAMINHO DO SEU ARQUIVO DE ÁUDIO" 

device = "cuda" if torch.cuda.is_available() else "cpu"

# Carregar modelo e processor
processor = WhisperProcessor.from_pretrained(MODEL_PATH)
model = WhisperForConditionalGeneration.from_pretrained(MODEL_PATH).to(device)

# Função de transcrição
def transcribe(audio_path):
    """
    Carrega um arquivo de áudio, reamostra, e retorna a transcrição.
    """
    # Carrega o áudio com librosa
    speech_array, sampling_rate = librosa.load(audio_path, sr=16000)
    
    # Processa o áudio
    input_features = processor(speech_array, sampling_rate=16000, return_tensors="pt").input_features
    
    # Move para o dispositivo correto
    input_features = input_features.to(device)
    
    # Gera a predição
    predicted_ids = model.generate(input_features)
    
    # Decodifica e retorna a transcrição
    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]
    return transcription

# Executa a transcrição e imprime ela
print(f"Transcrevendo o arquivo: {AUDIO_FILE_PATH}")
texto_transcrito = transcribe(AUDIO_FILE_PATH)
print("-" * 30)
print("Texto Transcrito:")
print(texto_transcrito)

print("-" * 30)

